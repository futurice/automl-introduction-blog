{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f610c619",
   "metadata": {},
   "source": [
    "# Train a model using AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broad-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "from autogluon.text import TextPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.text import TextPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.text import TextPredictor\n",
    "\n",
    "# Define a custom MultiLabelPredictor that actually wraps multiple text classifier inside\n",
    "class MultiLabelTextPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels: list,\n",
    "        problem_type: str = None,\n",
    "        eval_metric: str = None,\n",
    "        path: str = None,\n",
    "        verbosity: int = 3,\n",
    "        warn_if_exist: bool = True,\n",
    "        text_column: str = \"comment_text\",\n",
    "    ):\n",
    "\n",
    "        self.labels = labels\n",
    "        self.text_predictors = dict()\n",
    "        self.path = path\n",
    "        self.verbosity = verbosity\n",
    "        self.warn_if_exist = warn_if_exist\n",
    "        self.text_column = text_column\n",
    "        self.samples_per_class = 500\n",
    "\n",
    "        for label in self.labels:\n",
    "            self.text_predictors[label] = TextPredictor(\n",
    "                label=label,\n",
    "                problem_type=problem_type,\n",
    "                eval_metric=eval_metric,\n",
    "                path=os.path.join(path, label),\n",
    "                verbosity=verbosity,\n",
    "                warn_if_exist=warn_if_exist,\n",
    "            )\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_data: pd.DataFrame,\n",
    "        tuning_data: pd.DataFrame = None,\n",
    "        time_limit: int = None,\n",
    "    ) -> None:\n",
    "\n",
    "        for i, label in enumerate(self.labels):\n",
    "            print(\n",
    "                f\"Training a text classifier for class: {label} ({i}/{len(self.labels)})\"\n",
    "            )\n",
    "\n",
    "            temp_train_data = train_data  # .groupby(label, group_keys=False).apply(lambda x: x.sample(min(len(x), self.samples_per_class)))\n",
    "\n",
    "            self.text_predictors[label].fit(\n",
    "                train_data=temp_train_data[[self.text_column, label]],\n",
    "                time_limit=time_limit,\n",
    "            )\n",
    "\n",
    "    def predict(self, train_data: pd.DataFrame) -> np.array:\n",
    "\n",
    "        y_pred: np.array = np.zeros((train_data.shape[0], len(self.labels)))\n",
    "\n",
    "        for i, label in enumerate(self.labels):\n",
    "\n",
    "            y_pred[:, i] = self.text_predictors[label].predict(\n",
    "                train_data[[self.text_column]]\n",
    "            )\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        :type path: pathname where text classifiers are being stored\n",
    "        \"\"\"\n",
    "        for label in self.labels:\n",
    "            self.text_predictors[label] = TextPredictor.load(os.path.join(path, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "behavioral-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv.zip\", compression=\"zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "internal-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "french-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "data_dir = \"toxic-multilabel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "statutory-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(\n",
    "    columns=[\"id\"]\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "italic-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "turned-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = TabularDataset(train_df)\n",
    "val_df = TabularDataset(val_df)\n",
    "test_df = TabularDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "positive-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous runs\n",
    "!rm -rf toxic-multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac2d7b",
   "metadata": {},
   "source": [
    "## Train a MultiLabelTextPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9fd445",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cloudy-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/toxic\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/severe_toxic\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/obscene\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/threat\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/insult\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/identity_hate\"\n"
     ]
    }
   ],
   "source": [
    "predictor = MultiLabelTextPredictor(\n",
    "    labels=class_labels,\n",
    "    # problem_type='binary',\n",
    "    eval_metric=\"roc_auc\",\n",
    "    path=data_dir,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e1412",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a text classifier for class: toxic (0/6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem Type=\"binary\"\n",
      "Column Types:\n",
      "   - \"comment_text\": text\n",
      "   - \"toxic\": categorical\n",
      "\n",
      "The GluonNLP V0 backend is used. We will use 8 cpus and 1 gpus to train each trial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Logs will be saved to /home/jupyter/toxic-multilabel/toxic/task0/training.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting and transforming the train data...\n",
      "Done! Preprocessor saved to /home/jupyter/toxic-multilabel/toxic/task0/preprocessor.pkl\n",
      "Process dev set...\n",
      "Done!\n",
      "Max length for chunking text: 320, Stochastic chunk: Train-False/Test-False, Test #repeat: 1.\n",
      "#Total Params/Fixed Params=108990466/0\n",
      "Using gradient accumulation. Global batch size = 128\n",
      "Local training results will be saved to /home/jupyter/toxic-multilabel/toxic/task0/results_local.jsonl.\n",
      "[Iter 44/8790, Epoch 0] train loss=2.85e-01, gnorm=3.50e+00, lr=5.01e-06, #samples processed=5632, #sample per second=25.44. ETA=733.46min\n",
      "[Iter 88/8790, Epoch 0] train loss=1.71e-01, gnorm=2.38e+00, lr=1.00e-05, #samples processed=5632, #sample per second=25.08. ETA=734.98min\n",
      "[Iter 132/8790, Epoch 0] train loss=1.45e-01, gnorm=2.07e+00, lr=1.50e-05, #samples processed=5632, #sample per second=25.12. ETA=732.58min\n",
      "[Iter 176/8790, Epoch 0] train loss=1.49e-01, gnorm=1.12e+00, lr=2.00e-05, #samples processed=5632, #sample per second=25.29. ETA=728.28min\n",
      "[Iter 176/8790, Epoch 0] valid f1=7.4797e-01, mcc=7.2096e-01, roc_auc=9.7096e-01, accuracy=9.5040e-01, log_loss=1.2256e-01, time spent=43.745s, total time spent=15.62min. Find new best=True, Find new top-3=True\n"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_data=train_df, tuning_data=val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "focal-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumPy-shape semantics has been activated in your code. This is required for creating and manipulating scalar and zero-size tensors, which were not supported in MXNet before, as in the official NumPy library. Please DO NOT manually deactivate this semantics while using `mxnet.numpy` and `mxnet.numpy_extension` modules.\n"
     ]
    }
   ],
   "source": [
    "predictor.load(path=\"toxic-multilabel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd39f2",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = predictor.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(test_df[class_labels], y_test_pred))\n",
    "print(classification_report(test_df[class_labels], y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-matthew",
   "metadata": {},
   "source": [
    "## Predict real test samples\n",
    "(samples which true labels we dont know)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e30df",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arranged-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df = pd.read_csv(\"data/test.csv.zip\", compression=\"zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic = predictor.predict(real_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df = pd.DataFrame(predicted_toxic, columns=class_labels)\n",
    "predicted_toxic_df[\"id\"] = real_test_df[\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df[\n",
    "    [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df[\n",
    "    [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "].to_csv(\"toxic-challenge-autogluon.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
