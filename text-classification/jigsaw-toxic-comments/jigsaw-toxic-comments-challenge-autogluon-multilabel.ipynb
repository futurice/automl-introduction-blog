{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broad-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "from autogluon.text import TextPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.text import TextPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.text import TextPredictor\n",
    "\n",
    "\n",
    "class MultiLabelTextPredictor:\n",
    "\n",
    "    def __init__(self,\n",
    "                 labels: list,\n",
    "                 problem_type: str = None,\n",
    "                 eval_metric: str = None,\n",
    "                 path: str = None,\n",
    "                 verbosity: int = 3,\n",
    "                 warn_if_exist: bool = True,\n",
    "                 text_column: str = 'comment_text'):\n",
    "\n",
    "        self.labels = labels\n",
    "        self.text_predictors = dict()\n",
    "        self.path = path\n",
    "        self.verbosity = verbosity\n",
    "        self.warn_if_exist = warn_if_exist\n",
    "        self.text_column = text_column\n",
    "        self.samples_per_class = 500\n",
    "\n",
    "        for label in self.labels:\n",
    "            self.text_predictors[label] = TextPredictor(label=label,\n",
    "                                                        problem_type=problem_type,\n",
    "                                                        eval_metric=eval_metric,\n",
    "                                                        path=os.path.join(path, label),\n",
    "                                                        verbosity=verbosity,\n",
    "                                                        warn_if_exist=warn_if_exist)\n",
    "\n",
    "    def fit(self, train_data: pd.DataFrame,\n",
    "            tuning_data: pd.DataFrame = None, time_limit: int = None) -> None:\n",
    "\n",
    "        for i, label in enumerate(self.labels):\n",
    "            print(f'Training a text classifier for class: {label} ({i}/{len(self.labels)})')\n",
    "            \n",
    "            temp_train_data = train_data #.groupby(label, group_keys=False).apply(lambda x: x.sample(min(len(x), self.samples_per_class)))\n",
    "\n",
    "            self.text_predictors[label].fit(train_data=temp_train_data[[self.text_column, label]], time_limit=time_limit)\n",
    "\n",
    "    def predict(self, train_data: pd.DataFrame) -> np.array:\n",
    "\n",
    "        y_pred: np.array = np.zeros((train_data.shape[0], len(self.labels)))\n",
    "\n",
    "        for i, label in enumerate(self.labels):\n",
    "\n",
    "            y_pred[:, i] = self.text_predictors[label].predict(train_data[[self.text_column]])\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        :type path: pathname where text classifiers are being stored\n",
    "        \"\"\"\n",
    "        for label in self.labels:\n",
    "            self.text_predictors[label] = TextPredictor.load(os.path.join(path, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "behavioral-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "internal-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "french-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "data_dir = 'toxic-multilabel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "statutory-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['id']) #, 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "italic-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "turned-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = TabularDataset(train_df)\n",
    "val_df = TabularDataset(val_df)\n",
    "test_df = TabularDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "positive-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf toxic-multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "expensive-pleasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cloudy-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/toxic\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/severe_toxic\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/obscene\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/threat\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/insult\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"toxic-multilabel/identity_hate\"\n"
     ]
    }
   ],
   "source": [
    "predictor = MultiLabelTextPredictor(labels=class_labels,\n",
    "                          #problem_type='binary',\n",
    "                          eval_metric='roc_auc',\n",
    "                          path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a text classifier for class: toxic (0/6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem Type=\"binary\"\n",
      "Column Types:\n",
      "   - \"comment_text\": text\n",
      "   - \"toxic\": categorical\n",
      "\n",
      "The GluonNLP V0 backend is used. We will use 8 cpus and 1 gpus to train each trial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Logs will be saved to /home/jupyter/toxic-multilabel/toxic/task0/training.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting and transforming the train data...\n",
      "Done! Preprocessor saved to /home/jupyter/toxic-multilabel/toxic/task0/preprocessor.pkl\n",
      "Process dev set...\n",
      "Done!\n",
      "Max length for chunking text: 320, Stochastic chunk: Train-False/Test-False, Test #repeat: 1.\n",
      "#Total Params/Fixed Params=108990466/0\n",
      "Using gradient accumulation. Global batch size = 128\n",
      "Local training results will be saved to /home/jupyter/toxic-multilabel/toxic/task0/results_local.jsonl.\n",
      "[Iter 44/8790, Epoch 0] train loss=2.85e-01, gnorm=3.50e+00, lr=5.01e-06, #samples processed=5632, #sample per second=25.44. ETA=733.46min\n",
      "[Iter 88/8790, Epoch 0] train loss=1.71e-01, gnorm=2.38e+00, lr=1.00e-05, #samples processed=5632, #sample per second=25.08. ETA=734.98min\n",
      "[Iter 132/8790, Epoch 0] train loss=1.45e-01, gnorm=2.07e+00, lr=1.50e-05, #samples processed=5632, #sample per second=25.12. ETA=732.58min\n",
      "[Iter 176/8790, Epoch 0] train loss=1.49e-01, gnorm=1.12e+00, lr=2.00e-05, #samples processed=5632, #sample per second=25.29. ETA=728.28min\n",
      "[Iter 176/8790, Epoch 0] valid f1=7.4797e-01, mcc=7.2096e-01, roc_auc=9.7096e-01, accuracy=9.5040e-01, log_loss=1.2256e-01, time spent=43.745s, total time spent=15.62min. Find new best=True, Find new top-3=True\n"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_data=train_df,\n",
    "             tuning_data=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "focal-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumPy-shape semantics has been activated in your code. This is required for creating and manipulating scalar and zero-size tensors, which were not supported in MXNet before, as in the official NumPy library. Please DO NOT manually deactivate this semantics while using `mxnet.numpy` and `mxnet.numpy_extension` modules.\n"
     ]
    }
   ],
   "source": [
    "predictor.load(path='toxic-multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southwest-regular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbosity': None,\n",
       " '_label': 'severe_toxic',\n",
       " '_problem_type': 'binary',\n",
       " '_eval_metric': 'roc_auc',\n",
       " '_path': 'toxic-multilabel/severe_toxic/',\n",
       " '_model': <autogluon.text.text_prediction.mx.models.MultiModalTextModel at 0x7f0ff8bd5910>,\n",
       " '_fit_called': False,\n",
       " '_backend': 'gluonnlp_v0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.text_predictors['severe_toxic'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(test_df[class_labels], y_test_pred))\n",
    "print(classification_report(test_df[class_labels], y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arranged-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df = pd.read_csv('data/test.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic = predictor.predict(real_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rolled-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df = pd.DataFrame(predicted_toxic, columns=class_labels)\n",
    "predicted_toxic_df['id'] = real_test_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic_df[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('toxic-challenge-autogluon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "smaller-crest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 836M\n",
      "-rw-r--r-- 1 jupyter jupyter 1.9K Jul 30 06:57 LightGBM_compilation.log\n",
      "-rw-r--r-- 1 jupyter jupyter 1.1M Jul 30 06:44 Untitled.ipynb\n",
      "-rw-r--r-- 1 jupyter jupyter  37K Jul 30 07:49 Untitled1.ipynb\n",
      "drwxr-xr-x 4 jupyter jupyter 4.0K Jul 29 13:30 \u001b[0m\u001b[01;34magModels-predictClass\u001b[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter  14K Aug  5 12:56 collect-gcp-vertex-automl-batch-predictions.ipynb\n",
      "drwxr-xr-x 3 jupyter jupyter 4.0K Aug  5 17:43 \u001b[01;34mdata\u001b[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter  22K Aug 16 14:30 jigsaw-toxic-comments-challenge-autogluon-multilabel.ipynb\n",
      "-rw-r--r-- 1 jupyter jupyter  25K Aug  5 19:37 jigsaw-toxic-comments-challenge-autogluon.ipynb\n",
      "-rw-r--r-- 1 jupyter jupyter 2.6M Dec 11  2019 sample_submission.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 251M Jul 29 13:15 santander-customer-transaction-prediction.zip\n",
      "drwxr-xr-x 4 jupyter jupyter 4.0K Jul 29 13:49 \u001b[01;34msantander-models\u001b[0m/\n",
      "drwxr-xr-x 4 jupyter jupyter 4.0K Jul 30 07:18 \u001b[01;34msantander-models-2\u001b[0m/\n",
      "drwxr-xr-x 4 jupyter jupyter 4.0K Jul 30 07:49 \u001b[01;34msantander-models-3\u001b[0m/\n",
      "drwxr-xr-x 3 jupyter jupyter 4.0K Jul 29 12:47 \u001b[01;34msrc\u001b[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter 288M Dec 11  2019 test.csv\n",
      "drwxr-xr-x 5 jupyter jupyter 4.0K Aug  5 17:18 \u001b[01;34mtoxic\u001b[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter 6.0M Aug 16 14:29 toxic-challenge-autogluon.csv\n",
      "drwxr-xr-x 8 jupyter jupyter 4.0K Aug 13 18:29 \u001b[01;34mtoxic-multilabel\u001b[0m/\n",
      "drwxr-xr-x 3 jupyter jupyter 4.0K Aug  5 19:37 \u001b[01;34mtoxic_classifier\u001b[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter 289M Dec 11  2019 train.csv\n",
      "drwxr-xr-x 7 jupyter jupyter 4.0K Jul 29 12:47 \u001b[01;34mtutorials\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-crawford",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
