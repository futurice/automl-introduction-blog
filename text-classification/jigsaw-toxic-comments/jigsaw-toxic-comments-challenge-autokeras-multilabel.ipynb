{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee00391",
   "metadata": {},
   "source": [
    "## Train a neural network using AutoKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc589e8",
   "metadata": {},
   "source": [
    "## Set paths and other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5157a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_file = \"data/train.csv.zip\"\n",
    "BATCH_SIZE = 8 # It runs out-of-memmory quite easily :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "132cd403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38005729",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f57d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import autokeras as ak\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8d5f4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5334e0d",
   "metadata": {},
   "source": [
    "## Load ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4caf0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_input_file, compression=\"zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a82974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7208185",
   "metadata": {},
   "source": [
    "### Split ground truth dataset into training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a85f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129251, 8), (14362, 8), (15958, 8))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.1)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f50a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\n",
    "    [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ca14b",
   "metadata": {},
   "source": [
    "### Convert pandas dataframes into tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa394055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 05:48:35.067071: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-06 05:48:35.440316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.441356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-08-06 05:48:35.441433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-06 05:48:35.473985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-06 05:48:35.474120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-06 05:48:35.497275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-06 05:48:35.511668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-06 05:48:35.543670: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-06 05:48:35.555880: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-06 05:48:35.559149: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-06 05:48:35.559324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.560327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.562467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-06 05:48:35.564496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-06 05:48:35.564993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.565909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-08-06 05:48:35.566004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.566949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:35.567841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-06 05:48:35.569064: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-06 05:48:37.709953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-06 05:48:37.709993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-06 05:48:37.710003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-06 05:48:37.710243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:37.711226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:37.712165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 05:48:37.713073: E tensorflow/core/common_runtime/gpu/gpu_process_state.cc:69] TF_GPU_ALLOCATOR=cuda_malloc_async environment found, but TensorFlow was not compiled with CUDA 11.2+.\n",
      "2021-08-06 05:48:37.713106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15433 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        (train_df.comment_text.values,),\n",
    "        (\n",
    "            train_df[\n",
    "                [\n",
    "                    \"toxic\",\n",
    "                    \"severe_toxic\",\n",
    "                    \"obscene\",\n",
    "                    \"threat\",\n",
    "                    \"insult\",\n",
    "                    \"identity_hate\",\n",
    "                ]\n",
    "            ].values\n",
    "        ),\n",
    "    )\n",
    ").batch(BATCH_SIZE)\n",
    "val_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        (val_df.comment_text.values,),\n",
    "        (\n",
    "            val_df[\n",
    "                [\n",
    "                    \"toxic\",\n",
    "                    \"severe_toxic\",\n",
    "                    \"obscene\",\n",
    "                    \"threat\",\n",
    "                    \"insult\",\n",
    "                    \"identity_hate\",\n",
    "                ]\n",
    "            ].values\n",
    "        ),\n",
    "    )\n",
    ").batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35619283",
   "metadata": {},
   "source": [
    "## Train AutoKeras AutoML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac699a01",
   "metadata": {},
   "source": [
    "### Init AutoKeras text classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87c3e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./text_classifier/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./text_classifier/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "clf = ak.TextClassifier(\n",
    "    overwrite=False,  # True,\n",
    "    multi_label=True,\n",
    "    max_trials=10,\n",
    "    metrics=[tf.keras.metrics.AUC()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac14825",
   "metadata": {},
   "source": [
    "### Define earlystop to stop training if it does not improve anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e52bf2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e9f5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72f301",
   "metadata": {},
   "source": [
    "### Start training a text classifier using AutoKeras AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51615dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 05:48:42.879095: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-06 05:48:42.881597: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 05:49:15.570537: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_and_return_conditional_losses, word_embeddings_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, type_embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 945). These functions will not be directly callable after loading.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[earlystop],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5624516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "expand_last_dim (ExpandLastDim) (None, 1)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_tokenizer (BertTokenizer)  ((None, None), (None 0           expand_last_dim[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bert_encoder (BertEncoder)      (None, 768)          109482240   bert_tokenizer[0][0]             \n",
      "                                                                 bert_tokenizer[0][1]             \n",
      "                                                                 bert_tokenizer[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            4614        bert_encoder[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "classification_head_1 (Activati (None, 6)            0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,486,854\n",
      "Trainable params: 109,486,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the best model architecture\n",
    "clf.export_model().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa881a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c3ca28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[\n",
    "    [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa046090",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        (test_df.comment_text.values,),\n",
    "        (\n",
    "            test_df[\n",
    "                [\n",
    "                    \"toxic\",\n",
    "                    \"severe_toxic\",\n",
    "                    \"obscene\",\n",
    "                    \"threat\",\n",
    "                    \"insult\",\n",
    "                    \"identity_hate\",\n",
    "                ]\n",
    "            ].values,\n",
    "        ),\n",
    "    )\n",
    ").batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cc17a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(test_df.comment_text.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2caabf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990859527129107"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    test_df[\n",
    "        [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    ].values,\n",
    "    predicted_y,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "759664d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995/1995 [==============================] - 251s 125ms/step - loss: 0.0390 - auc: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03898276016116142, 0.9880177974700928]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b39fc06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796/1796 [==============================] - 222s 123ms/step - loss: 0.0390 - auc: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03896249458193779, 0.9869228005409241]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04533504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "expand_last_dim (ExpandLastDim) (None, 1)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_tokenizer (BertTokenizer)  ((None, None), (None 0           expand_last_dim[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bert_encoder (BertEncoder)      (None, 768)          109482240   bert_tokenizer[0][0]             \n",
      "                                                                 bert_tokenizer[0][1]             \n",
      "                                                                 bert_tokenizer[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            4614        bert_encoder[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "classification_head_1 (Activati (None, 6)            0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,486,854\n",
      "Trainable params: 109,486,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a946c2",
   "metadata": {},
   "source": [
    "## Predict unseen labels (for the Kaggle competition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb956bcb",
   "metadata": {},
   "source": [
    "### Load the actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ed886b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df = pd.read_csv(\"data/test.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d2cc0",
   "metadata": {},
   "source": [
    "### Predict unseen samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bede9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_pred = model.predict(real_test_df.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b6aba",
   "metadata": {},
   "source": [
    "### Combine predictions with sample ids to store result file in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20992eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(\n",
    "    real_test_pred,\n",
    "    columns=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"],\n",
    ")\n",
    "predictions_df[\"id\"] = real_test_df[\"id\"]\n",
    "predictions_df = predictions_df[\n",
    "    [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e4d4f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>0.511712</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.961040</td>\n",
       "      <td>0.757864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.988485      0.511712  0.979811  0.087071  0.961040   \n",
       "1  0000247867823ef7  0.000625      0.000057  0.000142  0.000085  0.000137   \n",
       "2  00013b17ad220c46  0.000909      0.000063  0.000141  0.000114  0.000116   \n",
       "3  00017563c3f7919a  0.000336      0.000108  0.000111  0.000152  0.000195   \n",
       "4  00017695ad8997eb  0.000703      0.000054  0.000142  0.000102  0.000122   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.757864  \n",
       "1       0.000059  \n",
       "2       0.000056  \n",
       "3       0.000107  \n",
       "4       0.000056  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions output looks like:\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfb062a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store prediction to be submitted to Kaggle\n",
    "predictions_df.to_csv(\"data/autokeras_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "autokeras",
   "language": "python",
   "name": "autokeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
